{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59f94550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_created</th>\n",
       "      <th>post_text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>favourites</th>\n",
       "      <th>statuses</th>\n",
       "      <th>retweets</th>\n",
       "      <th>URLs</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>637894677824413696</td>\n",
       "      <td>Sun Aug 30 07:48:37 +0000 2015</td>\n",
       "      <td>it is just over years since i was diagnosed wi...</td>\n",
       "      <td>1013187241</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['#anxiety', '#depression']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>637890384576778240</td>\n",
       "      <td>Sun Aug 30 07:31:33 +0000 2015</td>\n",
       "      <td>it is sunday i need a break so i am planning t...</td>\n",
       "      <td>1013187241</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['#A14']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>637749345908051968</td>\n",
       "      <td>Sat Aug 29 22:11:07 +0000 2015</td>\n",
       "      <td>awake but tired i need to sleep but my brain h...</td>\n",
       "      <td>1013187241</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>637696421077123073</td>\n",
       "      <td>Sat Aug 29 18:40:49 +0000 2015</td>\n",
       "      <td>bears make perfect gifts and are great for beg...</td>\n",
       "      <td>1013187241</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['#Retro', '#yay']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>637696327485366272</td>\n",
       "      <td>Sat Aug 29 18:40:26 +0000 2015</td>\n",
       "      <td>it is hard to say whether packing lists are ma...</td>\n",
       "      <td>1013187241</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['#movinghouse', '#anxiety']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              post_id                    post_created  \\\n",
       "0  637894677824413696  Sun Aug 30 07:48:37 +0000 2015   \n",
       "1  637890384576778240  Sun Aug 30 07:31:33 +0000 2015   \n",
       "2  637749345908051968  Sat Aug 29 22:11:07 +0000 2015   \n",
       "3  637696421077123073  Sat Aug 29 18:40:49 +0000 2015   \n",
       "4  637696327485366272  Sat Aug 29 18:40:26 +0000 2015   \n",
       "\n",
       "                                           post_text     user_id  followers  \\\n",
       "0  it is just over years since i was diagnosed wi...  1013187241         84   \n",
       "1  it is sunday i need a break so i am planning t...  1013187241         84   \n",
       "2  awake but tired i need to sleep but my brain h...  1013187241         84   \n",
       "3  bears make perfect gifts and are great for beg...  1013187241         84   \n",
       "4  it is hard to say whether packing lists are ma...  1013187241         84   \n",
       "\n",
       "   friends  favourites  statuses  retweets   URLs  Mentions  \\\n",
       "0      211         251       837         0  False     False   \n",
       "1      211         251       837         1  False     False   \n",
       "2      211         251       837         0  False     False   \n",
       "3      211         251       837         2   True      True   \n",
       "4      211         251       837         1  False     False   \n",
       "\n",
       "                       Hashtags  label  \n",
       "0   ['#anxiety', '#depression']      1  \n",
       "1                      ['#A14']      1  \n",
       "2                            []      1  \n",
       "3            ['#Retro', '#yay']      1  \n",
       "4  ['#movinghouse', '#anxiety']      1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(r'Mental-Health-Twitter-Preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b962f2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     it is just over years since i was diagnosed wi...\n",
       "1     it is sunday i need a break so i am planning t...\n",
       "2     awake but tired i need to sleep but my brain h...\n",
       "3     bears make perfect gifts and are great for beg...\n",
       "4     it is hard to say whether packing lists are ma...\n",
       "5                  making packing lists is my new hobby\n",
       "6     at what point does keeping stuff for nostalgic...\n",
       "7     currently in the findingboxesofrandomshit pack...\n",
       "8     cannot be bothered to cook take away on the wa...\n",
       "9     independent tv releases promo video for the fi...\n",
       "10          also i have too much stuff way way too much\n",
       "11      i never want to put one of these together again\n",
       "12    moving stuff is bloomin knackering and there i...\n",
       "13    back at the house moving stuff it is so peacef...\n",
       "14     urgh anxiety ffs where does it come from breathe\n",
       "Name: post_text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['post_text'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fdf3eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [it, is, just, over, years, since, i, was, dia...\n",
       "1        [it, is, sunday, i, need, a, break, so, i, am,...\n",
       "2        [awake, but, tired, i, need, to, sleep, but, m...\n",
       "3        [bears, make, perfect, gifts, and, are, great,...\n",
       "4        [it, is, hard, to, say, whether, packing, list...\n",
       "                               ...                        \n",
       "19761         [a, day, without, sunshine, is, like, night]\n",
       "19762    [borens, laws, when, in, charge, ponder, when,...\n",
       "19763    [the, flow, chart, is, a, most, thoroughly, ov...\n",
       "19764    [ships, are, safe, in, harbor, but, they, were...\n",
       "19765    [black, holes, are, where, god, is, dividing, ...\n",
       "Name: tokens, Length: 19766, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')  # Download tokenizer models\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize the post_text column\n",
    "df['tokens'] = df['post_text'].apply(lambda x: word_tokenize(x.lower()))\n",
    "df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "301428ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# # Download necessary resources\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def process_tokens(tokens):\n",
    "#     # Remove stopwords\n",
    "#     filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "#     # Lemmatize\n",
    "#     lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "#     return lemmatized_tokens\n",
    "\n",
    "# # Apply it\n",
    "# df['processed_tokens'] = df['tokens'].apply(process_tokens)\n",
    "# df['processed_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9489e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [it, be, just, over, year, since, i, be, diagn...\n",
       "1        [it, be, sunday, i, need, a, break, so, i, be,...\n",
       "2        [awake, but, tire, i, need, to, sleep, but, my...\n",
       "3        [bear, make, perfect, gift, and, be, great, fo...\n",
       "4        [it, be, hard, to, say, whether, pack, list, b...\n",
       "                               ...                        \n",
       "19761         [a, day, without, sunshine, be, like, night]\n",
       "19762    [borens, law, when, in, charge, ponder, when, ...\n",
       "19763    [the, flow, chart, be, a, most, thoroughly, ov...\n",
       "19764    [ship, be, safe, in, harbor, but, they, be, ne...\n",
       "19765    [black, hole, be, where, god, be, divide, by, ...\n",
       "Name: processed_tokens, Length: 19766, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopword(tokens):\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "df['processed_tokens'] = df['tokens'].apply(remove_stopword)\n",
    "\n",
    "# Convert POS tag from nltk format to wordnet format\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # default\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    return [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "\n",
    "\n",
    "df['processed_tokens'] = df['tokens'].apply(lemmatize_tokens)\n",
    "df['processed_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce3258c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "label_col = df.pop('label')\n",
    "\n",
    "df['label'] = label_col\n",
    "\n",
    "df.to_csv('Mental-Health-Twitter-Tokenized.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studysession",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
