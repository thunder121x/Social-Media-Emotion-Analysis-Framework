{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c5a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d1582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Data\n",
    "df_train = pd.read_csv('../resource/Mental-Health-Twitter-Tokenized/train.csv')\n",
    "df_val = pd.read_csv('../resource/Mental-Health-Twitter-Tokenized/val.csv')\n",
    "df_test = pd.read_csv('../resource/Mental-Health-Twitter-Tokenized/test.csv')\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X_train_text = df_train['processed_tokens']\n",
    "X_val_text = df_val['processed_tokens']\n",
    "X_test_text = df_test['processed_tokens']\n",
    "\n",
    "y_train = df_train['label']\n",
    "y_val = df_val['label']\n",
    "y_test = df_test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b78ad4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Text Vectorization (TF-IDF)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Convert processed tokens (list of tokens) to space-separated text\n",
    "X_train_text = X_train_text.apply(lambda x: ' '.join(eval(x)))\n",
    "X_val_text = X_val_text.apply(lambda x: ' '.join(eval(x)))\n",
    "X_test_text = X_test_text.apply(lambda x: ' '.join(eval(x)))\n",
    "\n",
    "# Transform the text data into TF-IDF features\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "X_val_tfidf = vectorizer.transform(X_val_text)\n",
    "X_test_tfidf = vectorizer.transform(X_test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d883ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = X_train_tfidf\n",
    "X_val_combined = X_val_tfidf\n",
    "X_test_combined = X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e8b4622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Numeric Features (followers, retweets, etc.)\n",
    "numeric_features_train = df_train[['followers', 'friends', 'favourites', 'statuses', 'retweets', 'URLs', 'Mentions']]\n",
    "numeric_features_val = df_val[['followers', 'friends', 'favourites', 'statuses', 'retweets', 'URLs', 'Mentions']]\n",
    "numeric_features_test = df_test[['followers', 'friends', 'favourites', 'statuses', 'retweets', 'URLs', 'Mentions']]\n",
    "\n",
    "# Standardize the numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_numeric = scaler.fit_transform(numeric_features_train)\n",
    "X_val_numeric = scaler.transform(numeric_features_val)\n",
    "X_test_numeric = scaler.transform(numeric_features_test)\n",
    "\n",
    "# Step 4: Combine Text and Numeric Features\n",
    "X_train_combined = X_train_tfidf\n",
    "X_val_combined = X_val_tfidf\n",
    "X_test_combined = X_test_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56083b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.72      1481\n",
      "           1       0.72      0.73      0.73      1484\n",
      "\n",
      "    accuracy                           0.72      2965\n",
      "   macro avg       0.72      0.72      0.72      2965\n",
      "weighted avg       0.72      0.72      0.72      2965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train the Model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_combined, y_train)\n",
    "\n",
    "# Step 6: Validation - Evaluate on the validation set\n",
    "y_val_pred = model.predict(X_val_combined)\n",
    "print(\"Validation Set Evaluation:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# # Step 7: After Validation, Train on the Full Training + Validation Data\n",
    "# X_full_train = hstack([X_train_combined, X_val_combined])\n",
    "# y_full_train = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "# # Re-train the model on the full training + validation data\n",
    "# model.fit(X_full_train, y_full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9e5a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation (Final Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      1482\n",
      "           1       0.71      0.72      0.71      1483\n",
      "\n",
      "    accuracy                           0.71      2965\n",
      "   macro avg       0.71      0.71      0.71      2965\n",
      "weighted avg       0.71      0.71      0.71      2965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Final Testing - Evaluate on the test set\n",
    "y_test_pred = model.predict(X_test_combined)\n",
    "print(\"Test Set Evaluation (Final Model):\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f8c492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74      1481\n",
      "           1       0.74      0.74      0.74      1484\n",
      "\n",
      "    accuracy                           0.74      2965\n",
      "   macro avg       0.74      0.74      0.74      2965\n",
      "weighted avg       0.74      0.74      0.74      2965\n",
      "\n",
      "Test Set Evaluation (Final Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      1482\n",
      "           1       0.74      0.73      0.73      1483\n",
      "\n",
      "    accuracy                           0.74      2965\n",
      "   macro avg       0.74      0.74      0.74      2965\n",
      "weighted avg       0.74      0.74      0.74      2965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_combined, y_train)\n",
    "# Step 6: Validation - Evaluate on the validation set\n",
    "y_val_pred = model.predict(X_val_combined)\n",
    "print(\"Validation Set Evaluation:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Step 8: Final Testing - Evaluate on the test set\n",
    "y_test_pred = model.predict(X_test_combined)\n",
    "print(\"Test Set Evaluation (Final Model):\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8965d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studysession",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
